{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "from collections import deque\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def read_a_graph(file_name):\n",
    "    %pwd\n",
    "    %cd /Users/AM/Documents/_Courses/Algorithms/Misc\n",
    "    # load a comma-delimited text file into an np matrix\n",
    "    resultList = {}\n",
    "    f = open(file_name, 'r')\n",
    "    for line in f:\n",
    "        aa = line.rstrip('\\n')  # \"1.0 \\t 2.0 \\t 3.0\"\n",
    "        sVals = aa.split('\\t')\n",
    "        sVals_s = sVals[:-1] # remove the last ''\n",
    "        intVals = list(map(np.int, sVals_s))  # [1.0, 2.0, 3.0]\n",
    "        resultList[intVals[0]] = intVals[1:]\n",
    "    \n",
    "    f.close()\n",
    "    out = resultList\n",
    "    return out#np.asarray(resultList, dtype=np.int)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "code_folding": [
     92,
     109,
     112,
     119,
     127,
     143,
     152
    ]
   },
   "outputs": [],
   "source": [
    "# Programming assignment 2.1 Programming assignment. MIN CUT\n",
    "class Graph(object):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.al = {} # adjacency list for the graph (self)\n",
    "        self.al_r = {} # adjacency list for the reversed graph (self)\n",
    "        self.max_i = 0 # max index of the graph nodes (or verteces)\n",
    "        self.explr = [] # exploration flags for DFF; \n",
    "        self.ft_r = [] # b - finishing time forvard\n",
    "                                        # c - finishing time reversed\n",
    "\n",
    "    \n",
    "    def read_direct(self, file_name):\n",
    "        %pwd\n",
    "        %cd /Users/AM/Documents/_Courses/Algorithms/Misc\n",
    "        # load a comma-delimited text file into an np matrix\n",
    "        resultList = {}\n",
    "        f = open(file_name, 'r')\n",
    "        max_i = self.max_i\n",
    "        for line in f:\n",
    "            line_s = line.rstrip('\\n')  # \"1.0 2.0 3.0\"    \n",
    "            sVals = line_s.split(' ')\n",
    "            sVals_s = sVals[:-1] # remove the last ''\n",
    "            intVals = list(map(np.int, sVals_s))  # [1.0, 2.0, 3.0]\n",
    "            if intVals[0] > max_i: max_i = intVals[0] # looking for a vertex with the max index\n",
    "            if intVals[1] > max_i: max_i = intVals[1]\n",
    "\n",
    "            if intVals[0] in resultList.keys(): \n",
    "                resultList[intVals[0]].append(intVals[1])\n",
    "            else:\n",
    "                resultList[intVals[0]] = [intVals[1]]\n",
    "        \n",
    "        f.close()\n",
    "        self.al = resultList\n",
    "        self.max_i = max_i\n",
    "        self.explr = [False for x in range(self.max_i + 1)]\n",
    "        self.ft = [0 for x in range(self.max_i + 1)]\n",
    "\n",
    "    \n",
    "    def read_reverse(self, file_name):\n",
    "        %pwd\n",
    "        %cd /Users/AM/Documents/_Courses/Algorithms/Misc\n",
    "        # load a comma-delimited text file into an np matrix\n",
    "        resultList = {}\n",
    "        f = open(file_name, 'r')\n",
    "        max_i = self.max_i ##!!!##to do - avoid the overwrite of max_i from read_direct\n",
    "                    \n",
    "        for line in f:\n",
    "            line_s = line.rstrip('\\n')  # \"1.0 2.0 3.0\"    \n",
    "            sVals = line_s.split(' ')\n",
    "            sVals_s = sVals[:-1] # remove the last ''\n",
    "            intVals = list(map(np.int, sVals_s))  # [1.0, 2.0, 3.0]\n",
    "            if intVals[0] > max_i: max_i = intVals[0] # looking for a vertex with the max index\n",
    "            if intVals[1] > max_i: max_i = intVals[1]\n",
    "            \n",
    "            if intVals[1] in resultList.keys(): \n",
    "                resultList[intVals[1]].append(intVals[0])\n",
    "            else:\n",
    "                resultList[intVals[1]] = [intVals[0]]\n",
    "        \n",
    "        f.close()\n",
    "        self.al_r = resultList\n",
    "        self.max_i = max_i\n",
    "        self.explr = [False for x in range(self.max_i + 1)]\n",
    "        self.ft_r = [0 for x in range(self.max_i + 1)]\n",
    "     \n",
    "    def dfs_rev(self):\n",
    "        self.explr = [False for x in range(self.max_i + 1)] # reset explored flags\n",
    "        q_dfs = deque([list(gr.al_r.keys())[0]]) # add to a dfs queue the first vertex \n",
    "        fin_time = 0\n",
    "        \n",
    "        while q_dfs:\n",
    "            i = q_dfs.pop() # take a next node to explore\n",
    "            self.explr[i] = True # mark as explored the node i\n",
    "            self.al_r[i].sort() # make a sorted and reversed list of all the nodes \n",
    "            self.al_r[i].reverse()   ### !!! ### it might be empty\n",
    "            a = self.al_r[i]    \n",
    "            \n",
    "            new_vertex_discovered = False\n",
    "            for ver in a:\n",
    "                if self.explr[ver] == False: # if we find a new vertex\n",
    "                    q_dfs.append(ver)\n",
    "                    self.explr[ver] = True \n",
    "                    new_vertex_discovered = True\n",
    "            if new_vertex_discovered == False:\n",
    "                fin_time += 1\n",
    "                self.ft_r[i] = fin_time\n",
    "\n",
    "        \n",
    "    \n",
    "#    def scc\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    def connect_vertices(self, v1,v2):\n",
    "        '''\n",
    "        Connect vertices v1 and v2 and removes edges between v1 and v2\n",
    "        Parallel edges from the newly formed verix (v1+v2) are not removed\n",
    "        '''\n",
    "        remaining_vertex = min(v1,v2)\n",
    "        disappearing_vertex = max(v1,v2)\n",
    "        self.al[remaining_vertex] += self.al[disappearing_vertex]\n",
    "            \n",
    "        # delete the second vertex    \n",
    "        del self.al[disappearing_vertex] \n",
    "        # replace disappearing vertex for remaining in all the verteces\n",
    "        for i in list(self.al):\n",
    "            while self.al[i].count(disappearing_vertex) !=0:\n",
    "                self.al[i].remove(disappearing_vertex)\n",
    "                self.al[i].append(remaining_vertex)\n",
    "        # remove edges from remaining to remaining vertex\n",
    "        while self.al[remaining_vertex].count(remaining_vertex) !=0:\n",
    "            self.al[remaining_vertex].remove(remaining_vertex)  \n",
    "    \n",
    "    def find_two_rand_vert(self, seed = 111):\n",
    "        '''choses two random verteces from the remaining in self.al'''\n",
    "        #ver1 = rnd.choice(list(self.al) ,1 , replace = False)\n",
    "        ver1 = rnd.choice(list(self.al.keys()))\n",
    "        ver2 = rnd.choice(list(self.al[ver1]))\n",
    "        return ver1, ver2\n",
    "    \n",
    "    def find_a_cut(self):\n",
    "        '''merge v1 and v2 verteces and removes the one with higher index\n",
    "        and returns number of remaining vert'''\n",
    "        while len(list(self.al)) > 2:\n",
    "            ver = self.find_two_rand_vert()\n",
    "            self.connect_vertices(ver[0], ver[1])\n",
    "        return len(self.al[list(self.al)[0]])    \n",
    "           \n",
    "    def find_min_cut(self):\n",
    "        '''by randomly merging by 2 verteces returns number of edges between the final two'''\n",
    "        min_cut_len = 1000 #len(list(self.al))\n",
    "        al_master = copy.deepcopy(self.al)\n",
    "        for i in range(30):\n",
    "            self.al = copy.deepcopy(al_master)\n",
    "            x = self.find_a_cut()\n",
    "            print('current iteration_',i, end = '\\r')\n",
    "            if min_cut_len > x: \n",
    "                min_cut_len = x\n",
    "                al_min_cut = copy.deepcopy(self.al)\n",
    "                print('\\r min_cut_len found after iteration_',i, 'is:', x, '\\n')\n",
    "\n",
    "        self.al = copy.deepcopy(al_master)\n",
    "        return min_cut_len, al_min_cut\n",
    "    \n",
    "    def test(self):\n",
    "        g = {1:[2,4,5], 2:[1,3], 3:[2,4,5], 4:[1,3,5], 5:[1,3,4]}\n",
    "        self.al = g\n",
    "        print('before connection\\n', self.al)\n",
    "        self.connect_vertices(5,2)\n",
    "        print('after 1st connection\\n', self.al)\n",
    "        self.connect_vertices(3,4)\n",
    "        print('after 2st connection\\n', self.al)\n",
    "\n",
    "    def test2(self):\n",
    "        g = {1:[2,4,5], 2:[1,3], 3:[2,4,5], 4:[1,3,5], 5:[1,3,4]}\n",
    "        self.al = g\n",
    "        print('before the test 2 \\n', self.al)\n",
    "        l = self.find_a_cut()\n",
    "        print('test results:\\n', self.al, 'length of the found cut', l)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/AM/Documents/_Courses/Algorithms/misc\n"
     ]
    }
   ],
   "source": [
    "gr = Graph()\n",
    "gr.read_direct('text4.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "875714"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gr.max_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/AM/Documents/_Courses/Algorithms/misc\n"
     ]
    }
   ],
   "source": [
    "gr.read_reverse('text4.txt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "875714"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gr.max_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "774055",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-152-1939dd293a0e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdfs_rev\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-147-7436fcc78459>\u001b[0m in \u001b[0;36mdfs_rev\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     73\u001b[0m             \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mq_dfs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# take a next node to explore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexplr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m \u001b[0;31m# mark as explored the node i\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mal_r\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# make a sorted and reversed list of all the nodes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mal_r\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreverse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mal_r\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 774055"
     ]
    }
   ],
   "source": [
    "gr.dfs_rev()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "5\n",
      "4\n",
      "3\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "a = [3,5,4,1,7]\n",
    "a.sort()\n",
    "a.reverse()\n",
    "for i in a:\n",
    "    print(i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
